}
if (grepl("wage",j)==FALSE) {
results.synth.temp <- EstimateSynth(j,cohort.series.synth.exclKing[variable == j,],
df_w,est.elast,"Synth_exclKing",PUMAs.Seattle, AllCombinations.ContigPUMAs, treated.periods,
aggr.method = "average", standardize = FALSE)
}
# Re-shape p-values
temp <- results.synth.temp$coeff %>% select(!starts_with("pval"))
pval_wide <- results.synth.temp$coeff %>% select(starts_with("pval"))
#Create vectors of pvalues
pval <- vector()
pval_rmspe <- vector()
pval.cum <- vector()
for (i in 1:9) {
pval[i] <- pval_wide[1, i]
pval_rmspe[i] <- pval_wide[1, 9 + i]
pval.cum[i] <- pval_wide[1, 18 + i] }
#Merge with coefficients
pval_long <- data.frame(T = seq(1:9), pval, pval_rmspe, pval.cum)
results.synth.temp$coeff <- merge(temp, pval_long, by = "T")
# Save the estimates with other variables
results.synth.exclKing <- rbind(results.synth.exclKing, results.synth.temp$coeff)
weights.synth.exclKing <- rbind(weights.synth.exclKing, results.synth.temp$weights)
bootstrap.synth.exclKing.TE[[j_index]] <- results.synth.temp$bootstrapTE
bootstrap.synth.exclKing.PUMAs[[j_index]] <- results.synth.temp$bootstrapPUMAs
bootstrap.synth.exclKing.Resid[[j_index]] <- results.synth.temp$bootstrapResid
bootstrap.synth.exclKing.TEcum[[j_index]] <- results.synth.temp$bootstrapTEcum
}
#saveRDS(results.synth.exclKing,paste0(path.to.save,stub.save,"_synth_exclKing_",mode.changes,".Rds"))
#saveRDS(weights.synth.exclKing,paste0(path.to.save,stub.save,"_synth_weights_exclKing_",mode.changes,".Rds"))
#saveRDS(bootstrap.synth.exclKing.TE,paste0(path.to.save,stub.save,"_synth_bootstrapTE_exclKing_",mode.changes,".Rds"))
#saveRDS(bootstrap.synth.exclKing.TEcum,paste0(path.to.save,stub.save,"_synth_bootstrapTEcum_exclKing_",mode.changes,".Rds"))
#saveRDS(bootstrap.synth.exclKing.PUMAs,paste0(path.to.save,stub.save,"_synth_bootstrapPUMAs_exclKing_",mode.changes,".Rds"))
#saveRDS(bootstrap.synth.exclKing.Resid,paste0(path.to.save,stub.save,"_synth_bootstrapResid_exclKing_",mode.changes,".Rds"))
#############################################################################
### Save all estimation results in one RDS file to use in future analysis ###
#############################################################################
results.coefs.all <- results.synth.exclKing
saveRDS(results.coefs.all, file = paste0(path.to.save,stub.save,"_coef_CI_",mode.changes,".Rds"))
print(paste("File",paste0(path.to.save,stub.save,"_coef_CI_",mode.changes,".Rds"),"saved"))
#################################
### Levels Columns of Table 6 ###
#################################
# Why are we using pval.cum here? In paper we report just pval
results.coefs.best <- results.coefs.all
setnames(results.coefs.best,"variable","variable_name")
results.coefs.best <- data.table(results.coefs.best, key = c("method","variable_name","T"))
results.coefs.best$sig[results.coefs.best$pval.cum > 0.1] <- ""
results.coefs.best$sig[results.coefs.best$pval.cum <= 0.1] <- "*"
results.coefs.best$sig[results.coefs.best$pval.cum <= 0.05] <- "**"
results.coefs.best$sig[results.coefs.best$pval.cum <= 0.01] <- "***"
results.coefs.best[ , coefcum_text := paste0(as.character(round(coefcum,3)),sig)]
results.coefs.best[ , pvalcum_text := paste0("[",as.character(round(pval.cum,3)),"]")]
table.to.save <- results.coefs.best[ , c("variable_name","method","T","coefcum_text","pvalcum_text")]
table.to.save <- melt(table.to.save, id.vars = c("variable_name","method","T"))
table.to.save <- dcast(table.to.save, T + variable ~ variable_name + method)
table.to.save.addl <- unique(results.coefs.best[grepl("18",variable_name) & is.element(method,c("Synth_exclKing","Int_FE_exlKing")), c("variable_name","method","RMSE","Obs")])
table.to.save.addl[ , RMSE := as.character(round(RMSE,3))]
table.to.save.addl[is.na(RMSE) , RMSE := ""]
table.to.save.addl[ , T := 10 ]
table.to.save.addl <- melt(table.to.save.addl, id.vars = c("variable_name","method","T"))
table.to.save.addl[variable=="RMSE"  , T := 22 ]
table.to.save.addl[variable=="Obs"  , T := 23 ]
table.to.save.addl <- dcast(table.to.save.addl, T + variable ~  variable_name + method)
write.csv(rbind(as.matrix(table.to.save),as.matrix(table.to.save.addl)), file = paste0(path.to.save,stub.save,"_",mode.changes,".csv"))
###########################
###                     ###
### Paths and filenames ###
###                     ###
###########################
# What's the root folder for everything?
path.to.root <- "R:\\Project\\SeattleMinimumWage\\Stata\\AttenuationPaper\\dofiles\\AEJEP_submission_2020\\"
# Where is the data?
path.to.data <- paste0(path.to.root,"data\\")
# Where should results be saved?
path.to.save <- paste0(path.to.root,"output\\")
# Stub to load the data
stub <- "establishments_samplesize100synth_cumulative_prep_food"
# Stub to save the results
stub.save <- "jobs_cumulative_food"
mode.changes = "growth_rates"
#######################
###                 ###
### Define outcomes ###
###                 ###
#######################
# Wage bins -- from jobs paying (<=$9.99) to (<=$39.99)
#wge <- seq(9,40)
wge = c(40) # Jobs paying <$19
# Stubs for outcomes -- variables
var <- c("d_cum_nworkers_beg","d_cum_mean_wagerate","d_cum_payroll_flow","d_cum_hours_flow")
# Note on variable notation:
# d_cum_hours_flow -- year-over-year change in hours worked in jobs paying <=w.99, where w=18 for example
# d_cum_nworkers_beg -- year-over-year change in number of beginning-of-quarter jobs paying <=w.99, where w=18 for example
# d_cum_mean_wagerate -- year-over-year change in average wage rate (weighted by hours) in jobs paying <=w.99, where w=18 for example
# d_cum_payroll_flow -- year-over-year change in total payroll to jobs paying <=w.99, where w=18 for example
# Build a vector of outcomes to use in regressions
outcomes <- c()
for(i in var){
for(j in wge){
outcomes <- c(outcomes,paste0(i,j))
}
}
#############################
###                       ###
### Load the data         ###
### for synthetic control ###
### and interactive FE    ###
###                       ###
#############################
cohort.series <- read.dta13(paste0(path.to.data,stub,".dta", collapse = ""))
cohort.series <- data.table(cohort.series, key = c("region0","yearquarter"))
# Melt for analysis
cohort.series <- melt(cohort.series, id.vars = c("region0","puma_id0","yearquarter","R"))
cohort.series <- data.table(cohort.series, key = c("region0","puma_id0","yearquarter","variable"))
cohort.series.N <- cohort.series[substr(variable,1,2)=="L4", list(variable,yearquarter,puma_id0,region0,value)]
cohort.series.N <- cohort.series.N[is.na(value)==FALSE, ]
# Wage cutoff
cohort.series[ , w := as.integer(gsub("[a-z\\_]+([0-9]+)","\\1",variable))]
cohort.series.N[ , w := as.integer(gsub("L4\\_([a-z\\_]+)([0-9]+)","\\2",variable))]
cohort.series.N[ , stub_N := (gsub("([a-z\\_]+)([0-9]+)","\\1",variable))]
setnames(cohort.series.N,"value","N")
cohort.series.N[ , variable := NULL]
# Add year variable
cohort.series[ , year := floor(yearquarter/10) ]
# Drop if variable is not one of the outcomes of interest!
cohort.series <- cohort.series[is.element(variable,outcomes), ]
cohort.series <- cohort.series[region0!=0 & region0!=9 & is.na(puma_id0)==F & puma_id0!=0, ]
# Region - PUMA ID
cohort.series[ , region_puma_id0 := region0 * 1e5 + puma_id0]
# Drop 2005 & 20164 cohort -- N/A for flows
cohort.series <- cohort.series[yearquarter > 20061, ]
cohort.series <- cohort.series[yearquarter != 20164, ]
cohort.series[ , dY := value]
# Eliminate PUMAS with at least one missing obs. in any variable #
cohort.series[, max_dY := max(dY), by = "region_puma_id0"]
cohort.series[, n_dY := sum(is.na(dY)), by = c("region_puma_id0","variable")]
print("PUMAs with missing data:")
print(unique(cohort.series[is.na(max_dY), region_puma_id0]))
cohort.series <- cohort.series[is.na(max_dY)==F, ]
cohort.series$max_dY <- NULL
# Eliminate PUMAs codes with fewer than 10 observations (i.e. pre-policy + policy years)
cohort.series[ , n_obs := length(yearquarter), by = c("region_puma_id0","variable")]
cohort.series[ , max_n_obs := max(n_obs), by = "region_puma_id0"]
max.obs = cohort.series[ , max(max_n_obs)]
unique(cohort.series[max_n_obs < max.obs, region_puma_id0])
cohort.series <- cohort.series[max_n_obs==max.obs, ]
cohort.series$n_obs <- NULL
cohort.series$max_n_obs <- NULL
print("Number of PUMAs for Synthetic Control and Interactive FE (incl. 5 PUMAs in Seattle):")
print(length(unique(cohort.series$region_puma_id0[is.element(cohort.series$region0,c(1,4,5))])))
# Merge lagged number of hours and lagged number of workers for averaging
cohort.series[grepl("nworkers",variable)==TRUE, stub_N := "L4_cum_nmworkers"]
cohort.series[grepl("nworkers",variable)==FALSE, stub_N := "L4_cum_hours"]
cohort.series <- merge(cohort.series, cohort.series.N, by = c("puma_id0","region0","yearquarter","w","stub_N"), all.x = TRUE, allow.cartesian = TRUE)
#######################################################
### To use contiguous PUMAs for SCM s.e.            ###
### List neighbors for each PUMA in WA              ###
### excl. King County outside of Seattle and SeaTac ###
#######################################################
# Load the file with all possible combinations of
# 5 contiguous PUMAs in WA outside of King County
AllCombinations.ContigPUMAs <- readRDS(file = paste0(path.to.data,"PUMA_unique_combinations.RDS"))
########################################
###                                  ###
###        Analysis Part 2           ###
### Synthetic Control                ###
### Using non-Seattle PUMAS in WA    ###
### as control regions               ###
###                                  ###
########################################
###################################
### PUMAS excluding King County ###
###################################
# Keep only relevant variables
cohort.series.synth.exclKing <- cohort.series[region0 != 2 & region0 != 3 & region0!=9 ,
c("variable","region0","region_puma_id0","yearquarter","dY", "N"), with = F]
# Initialize results data.frames -- coefficients
results.synth.exclKing <- data.frame(variable = character(),
method = character(),
T = integer(),
dY = double(),
coef = double(),
coef.w = double(),
stringsAsFactors = FALSE)
weights.synth.exclKing <- data.frame(variable = character(),
region_puma_id0 = integer(),
weights = double(),
stringsAsFactors = FALSE)
# Set Treated periods
treated.periods <- c("20143","20144", "20151" ,"20152","20153","20154","20161","20162","20163")
bootstrap.synth.exclKing.TE <- list()
bootstrap.synth.exclKing.TEcum <- list()
bootstrap.synth.exclKing.PUMAs <- list()
bootstrap.synth.exclKing.Resid <- list()
for (j in outcomes) {
j_index = match(j,outcomes)
print("ESTIMATING SYNTHETIC CONTROL TE USING PUMAS EXCLUDING KING COUNTY")
print(paste("Working on variable:",j))
### How many PUMAS in Seattle? Average the outcomes to form 1 unit
PUMAs.Seattle <- unique(cohort.series.synth.exclKing[variable == j & region0 == 1, region_puma_id0])
# Employment variable? Then estimate wage effect as well
est.elast = 0
if (est.elast == 1) {
var_w = paste0("d_cum_mean_wagerate",gsub("[a-z\\_]+([0-9]+)","\\1",j))
df_w = cohort.series.synth.exclKing[variable == var_w,]
}
if (est.elast == 0) {
df_w = NULL
}
# Get the estimates
if (grepl("wage",j)) {
results.synth.temp <- EstimateSynth(j,cohort.series.synth.exclKing[variable == j,],
df_w,est.elast,"Synth_exclKing",PUMAs.Seattle, AllCombinations.ContigPUMAs, treated.periods,
aggr.method = "average", standardize = FALSE)
}
if (grepl("wage",j)==FALSE) {
results.synth.temp <- EstimateSynth(j,cohort.series.synth.exclKing[variable == j,],
df_w,est.elast,"Synth_exclKing",PUMAs.Seattle, AllCombinations.ContigPUMAs, treated.periods,
aggr.method = "average", standardize = FALSE)
}
# Re-shape p-values
temp <- results.synth.temp$coeff %>% select(!starts_with("pval"))
pval_wide <- results.synth.temp$coeff %>% select(starts_with("pval"))
#Create vectors of pvalues
pval <- vector()
pval_rmspe <- vector()
pval.cum <- vector()
for (i in 1:9) {
pval[i] <- pval_wide[1, i]
pval_rmspe[i] <- pval_wide[1, 9 + i]
pval.cum[i] <- pval_wide[1, 18 + i] }
#Merge with coefficients
pval_long <- data.frame(T = seq(1:9), pval, pval_rmspe, pval.cum)
results.synth.temp$coeff <- merge(temp, pval_long, by = "T")
# Save the estimates with other variables
results.synth.exclKing <- rbind(results.synth.exclKing, results.synth.temp$coeff)
weights.synth.exclKing <- rbind(weights.synth.exclKing, results.synth.temp$weights)
bootstrap.synth.exclKing.TE[[j_index]] <- results.synth.temp$bootstrapTE
bootstrap.synth.exclKing.PUMAs[[j_index]] <- results.synth.temp$bootstrapPUMAs
bootstrap.synth.exclKing.Resid[[j_index]] <- results.synth.temp$bootstrapResid
bootstrap.synth.exclKing.TEcum[[j_index]] <- results.synth.temp$bootstrapTEcum
}
#saveRDS(results.synth.exclKing,paste0(path.to.save,stub.save,"_synth_exclKing_",mode.changes,".Rds"))
#saveRDS(weights.synth.exclKing,paste0(path.to.save,stub.save,"_synth_weights_exclKing_",mode.changes,".Rds"))
#saveRDS(bootstrap.synth.exclKing.TE,paste0(path.to.save,stub.save,"_synth_bootstrapTE_exclKing_",mode.changes,".Rds"))
#saveRDS(bootstrap.synth.exclKing.TEcum,paste0(path.to.save,stub.save,"_synth_bootstrapTEcum_exclKing_",mode.changes,".Rds"))
#saveRDS(bootstrap.synth.exclKing.PUMAs,paste0(path.to.save,stub.save,"_synth_bootstrapPUMAs_exclKing_",mode.changes,".Rds"))
#saveRDS(bootstrap.synth.exclKing.Resid,paste0(path.to.save,stub.save,"_synth_bootstrapResid_exclKing_",mode.changes,".Rds"))
#############################################################################
### Save all estimation results in one RDS file to use in future analysis ###
#############################################################################
results.coefs.all <- results.synth.exclKing
saveRDS(results.coefs.all, file = paste0(path.to.save,stub.save,"_coef_CI_",mode.changes,".Rds"))
print(paste("File",paste0(path.to.save,stub.save,"_coef_CI_",mode.changes,".Rds"),"saved"))
#################################
### Levels Columns of Table 6 ###
#################################
# Why are we using pval.cum here? In paper we report just pval
results.coefs.best <- results.coefs.all
setnames(results.coefs.best,"variable","variable_name")
results.coefs.best <- data.table(results.coefs.best, key = c("method","variable_name","T"))
results.coefs.best$sig[results.coefs.best$pval.cum > 0.1] <- ""
results.coefs.best$sig[results.coefs.best$pval.cum <= 0.1] <- "*"
results.coefs.best$sig[results.coefs.best$pval.cum <= 0.05] <- "**"
results.coefs.best$sig[results.coefs.best$pval.cum <= 0.01] <- "***"
results.coefs.best[ , coefcum_text := paste0(as.character(round(coefcum,3)),sig)]
results.coefs.best[ , pvalcum_text := paste0("[",as.character(round(pval.cum,3)),"]")]
table.to.save <- results.coefs.best[ , c("variable_name","method","T","coefcum_text","pvalcum_text")]
table.to.save <- melt(table.to.save, id.vars = c("variable_name","method","T"))
table.to.save <- dcast(table.to.save, T + variable ~ variable_name + method)
table.to.save.addl <- unique(results.coefs.best[grepl("18",variable_name) & is.element(method,c("Synth_exclKing","Int_FE_exlKing")), c("variable_name","method","RMSE","Obs")])
table.to.save.addl[ , RMSE := as.character(round(RMSE,3))]
table.to.save.addl[is.na(RMSE) , RMSE := ""]
table.to.save.addl[ , T := 10 ]
table.to.save.addl <- melt(table.to.save.addl, id.vars = c("variable_name","method","T"))
table.to.save.addl[variable=="RMSE"  , T := 22 ]
table.to.save.addl[variable=="Obs"  , T := 23 ]
table.to.save.addl <- dcast(table.to.save.addl, T + variable ~  variable_name + method)
write.csv(rbind(as.matrix(table.to.save),as.matrix(table.to.save.addl)), file = paste0(path.to.save,stub.save,"_",mode.changes,".csv"))
# This file estimates the impact of LLM in Seattle
# Note: stata files need to be saved in 2013 format
rm(list = ls())
setwd("R:\\Project\\SeattleMinimumWage\\Stata\\Instability\\SeattlePSL\\output\\TE\\")
#install.packages('devtools', repos = 'http://cran.us.r-project.org') # if not already installed
#devtools::install_github('xuyiqing/gsynth')
3### Load libraries ###
#install.packages("readstata13")
library(readstata13)
library(sandwich)
library(stringr)
library(parallel)
library(gsynth)
library(panelView)
library(dplyr)
library(devtools)
set.seed(490289)
###########################
### Paths and filenames ###
###########################
# What's the root folder for everything?
path.to.root <- "R:\\Project\\SeattleMinimumWage\\Stata\\Instability\\"
# Where is the data?
path.to.data <- paste0(path.to.root,"SeattlePSL\\data\\")
# Where should results be saved?
path.to.save <- paste0(path.to.root,"SeattlePSL\\output\\TE\\")
###Arguments
##Main analysis
sep=0
full=1
tf =201113
stubdata <- "jobs_02_samplesize100synth_cum_all_growth0_4_250FTE"
# # ##Separations analysis
# sep=1
# full= 0
# # tf =201416
# # stubdata <- "jobs_all_samplesize100synth_cumulative_worker_w19FG2"
# tf =201113
# stubdata<-"jobs_all_samplesize100synth_cumulative_worker_w19FG2PSL"
#######################
###                 ###
### Define outcomes ###
###                 ###
#######################
# Wage bins -- from jobs paying (<=$9.99) to (<=$39.99)
#wge <- seq(9,49)
# Wage bins -- from jobs paying (<=$9.99) to (<=$49.99)
wge = 49
# Stubs for outcomes -- variables
#var <- c(  "d_cum_hired_beg", "d_cum_separates_beg",  "d_cum_turnover_beg" )
if (sep!=1 & full==0){
var <- c("d_cum_nworkers_beg", "d_cum_earnings_beg",  "d_cum_hired_flow", "d_cum_separates_flow", "d_cum_turnover_flow", "d_cum_mean_wagerate")
}
if (sep!=1 & full==1){
var <- c("d_cum_nworkers_blt1", "d_cum_earnings_blt1", "d_cum_hired_lt1", "d_cum_separates_lt1", "d_cum_turnover_lt1"
,"d_cum_nworkers_full", "d_cum_earnings_full", "d_cum_hired_full", "d_cum_separates_full", "d_cum_turnover_full")
}
if (sep==1){
var <- c("d_cum_separates_EE", "d_cum_separates_EU", "d_cum_separates_EN",
"d_cum_separates_fullEE", "d_cum_separates_fullEU", "d_cum_separates_fullEN",
"d_cum_separates_lt1EE", "d_cum_separates_lt1EU", "d_cum_separates_lt1EN",
"d_cum_nonemp_hrate", "d_cum_nonemp_srate", "d_cum_hired_earnings", "d_cum_separates_earnings")
}
# Build a vector of outcomes to use in regressions
outcomes <- c()
for(i in var){
for(j in wge){
outcomes <- c(outcomes,paste0(i,j))
}
}
#############################
###### Main analysis ########
## Firm group > 4 & < 250 ###
#############################
tseries <- read.dta13(paste0(path.to.data,stubdata,".dta", collapse = ""))
tseries <-data.frame(tseries)
keep <- c(outcomes, "yearquarter", "region_time", "region_wage49", "region0", "pop", "puma_id0", "D")
tseries.analysis<-tseries[keep]
tseries.analysis$region_puma_id0= tseries.analysis$region0 * 1e5 + tseries.analysis$puma_id0
tseries.analysis <- tseries.analysis[tseries.analysis$region0!=0 & tseries.analysis$region0!=9  & tseries.analysis$region0!=2  & tseries.analysis$region0!=3, ]
tseries.analysis<- tseries.analysis[tseries.analysis$puma_id0!=0 ,]
# & tseries.analysis$puma_id0!=11606 & tseries.analysis$puma_id0!=11607 &tseries.analysis$puma_id0!=11608
# &tseries.analysis$puma_id0!=11609 & tseries.analysis$puma_id0!=11610 & tseries.analysis$puma_id0!=11611 & tseries.analysis$puma_id0!=11612, ]
if (tf == 201113 & full==1) {
tseries.analysis<- tseries.analysis[tseries.analysis$yearquarter<2014 & tseries.analysis$yearquarter>=2006.4, ]
}
if (tf == 201113 & full==0) {
tseries.analysis<- tseries.analysis[tseries.analysis$yearquarter<2014 & tseries.analysis$yearquarter>=2006.375, ]
}
data <- tseries.analysis
out <- gsynth(d_cum_nworkers_full49~D , data = data, index=c("puma_id0", "yearquarter"),
force = "two-way", CV = TRUE, r = c(0, 5), se = TRUE, inference = "parametric", nboots = 10000, parallel = TRUE, cores=20)
avgTE_FG2.1<-round(data.frame(out$est.avg, out$r.cv, out$MSPE, out$T*out$N), digits=3)
avgTE_FG2.1$variable <- "Nworkers"
out <- gsynth(d_cum_earnings_full49~D  + pop , data = data, index=c("puma_id0", "yearquarter"),
force = "two-way", CV = TRUE, r = c(0, 5), se = TRUE, inference = "parametric", nboots = 10000, parallel = TRUE, cores=20)
avgTE_FG2.2<-round(data.frame(out$est.avg, out$r.cv, out$MSPE, out$T*out$N), digits=3)
avgTE_FG2.2$variable <- "Earnings"
#	panelView(d_cum_hired_full49~D, data = data, index=c("puma_id0", "yearquarter"), type = "outcome", main="")
out <- gsynth(d_cum_hired_full49~D + pop   , data = data, index=c("puma_id0", "yearquarter"),
force = "two-way", CV = TRUE, r = c(0, 5), se = TRUE, inference = "parametric", nboots = 10000, parallel = TRUE, cores=20)
avgTE_FG2.3<-round(data.frame(out$est.avg, out$r.cv, out$MSPE, out$T*out$N), digits=3)
avgTE_FG2.3$variable <- "Hired"
#	panelView(d_cum_separates_full49~D, data = data, index=c("puma_id0", "yearquarter"), type = "outcome", main="")
out <- gsynth(d_cum_separates_full49~D + pop  , data = data, index=c("puma_id0", "yearquarter"),
force = "two-way", CV = TRUE, r = c(0, 5), se = TRUE, inference = "parametric", nboots = 10000, parallel = TRUE, cores=20)
avgTE_FG2.4<-round(data.frame(out$est.avg, out$r.cv, out$MSPE, out$T*out$N), digits=3)
avgTE_FG2.4$variable <- "Separates"
#	panelView(d_cum_turnover_full49~D, data = data, index=c("puma_id0", "yearquarter"), type = "outcome", main="")
out <- gsynth(d_cum_turnover_full49~D   + pop , data = data, index=c("puma_id0", "yearquarter"),
force = "two-way", CV = TRUE, r = c(0, 5), se = TRUE, inference = "parametric", nboots = 10000, parallel = TRUE, cores=20)
avgTE_FG2.5<-round(data.frame(out$est.avg, out$r.cv, out$MSPE, out$T*out$N), digits=3)
avgTE_FG2.5$variable <- "Turnover"
full_avg_FG2<-rbind(as.matrix(avgTE_FG2.1), as.matrix(avgTE_FG2.2), as.matrix(avgTE_FG2.3)
, as.matrix(avgTE_FG2.4), as.matrix(avgTE_FG2.5) )
full_avg_FG2<- as.data.frame(full_avg_FG2)
full_avg_FG2$pval <- ifelse(full_avg_FG2$p.value < .1 & full_avg_FG2$p.value>=.05 , "*", ifelse(full_avg_FG2$p.value < .05
& full_avg_FG2$p.value >=.01 , "**",  ifelse(full_avg_FG2$p.value < .01 , "***", "")))
write.csv(full_avg_FG2, file = paste0(path.to.save,tf,"full_avg_FG2.csv"))
data <-data[complete.cases(data), ]
#	panelView(d_cum_nworkers_blt149~D, data=data, index=c("puma_id0", "yearquarter"), pre.post=TRUE)
#	panelView(d_cum_nworkers_blt149~D  + pop , data = data, index=c("puma_id0", "yearquarter"), type = "outcome", main="")
out <- gsynth(d_cum_nworkers_blt149~D , data = data, index=c("puma_id0", "yearquarter"),
force = "two-way", CV = TRUE, r = c(0, 5), se = TRUE, inference = "parametric", nboots = 10000, parallel = TRUE, cores=20)
avgTE_FG2.1<-round(data.frame(out$est.avg, out$r.cv, out$MSPE, out$T*out$N), digits=3)
avgTE_FG2.1$variable <- "Nworkers"
#	panelView(d_cum_earnings_blt149~D, data = data, index=c("puma_id0", "yearquarter"), type = "outcome", main="")
out <- gsynth(d_cum_earnings_blt149~D  + pop , data = data, index=c("puma_id0", "yearquarter"),
force = "two-way", CV = TRUE, r = c(0, 5), se = TRUE, inference = "parametric", nboots = 10000, parallel = TRUE, cores=20)
avgTE_FG2.2<-round(data.frame(out$est.avg, out$r.cv, out$MSPE, out$T*out$N), digits=3)
avgTE_FG2.2$variable <- "Earnings"
#	panelView(d_cum_hired_lt149~D, data = data, index=c("puma_id0", "yearquarter"), type = "outcome", main="")
out <- gsynth(d_cum_hired_lt149~D   + pop , data = data, index=c("puma_id0", "yearquarter"),
force = "two-way", CV = TRUE, r = c(0, 5), se = TRUE, inference = "parametric", nboots = 10000, parallel = TRUE, cores=20)
avgTE_FG2.3<-round(data.frame(out$est.avg, out$r.cv, out$MSPE, out$T*out$N), digits=3)
avgTE_FG2.3$variable <- "Hired"
#	panelView(d_cum_separates_lt149~D, data = data, index=c("puma_id0", "yearquarter"), type = "outcome", main="")
out <- gsynth(d_cum_separates_lt149~D + pop  , data = data, index=c("puma_id0", "yearquarter"),
force = "two-way", CV = TRUE, r = c(0, 5), se = TRUE, inference = "parametric", nboots = 10000, parallel = TRUE, cores=20)
avgTE_FG2.4<-round(data.frame(out$est.avg, out$r.cv, out$MSPE, out$T*out$N), digits=3)
avgTE_FG2.4$variable <- "Separates"
#	panelView(d_cum_turnover_lt149~D, data = data, index=c("puma_id0", "yearquarter"), type = "outcome", main="")
out <- gsynth(d_cum_turnover_lt149~D  + pop  , data = data, index=c("puma_id0", "yearquarter"),
force = "two-way", CV = TRUE, r = c(0, 5), se = TRUE, inference = "parametric", nboots = 10000, parallel = TRUE, cores=20)
avgTE_FG2.5<-round(data.frame(out$est.avg, out$r.cv, out$MSPE, out$T*out$N), digits=3)
avgTE_FG2.5$variable <- "Turnover"
lt1_avg_FG2<-rbind(as.matrix(avgTE_FG2.1), as.matrix(avgTE_FG2.2), as.matrix(avgTE_FG2.3)
, as.matrix(avgTE_FG2.4), as.matrix(avgTE_FG2.5) )
lt1_avg_FG2<- as.data.frame(lt1_avg_FG2)
lt1_avg_FG2$pval <- ifelse(lt1_avg_FG2$p.value < .1 & lt1_avg_FG2$p.value>=.05 , "*", ifelse(lt1_avg_FG2$p.value < .05
& lt1_avg_FG2$p.value >=.01 , "**",  ifelse(lt1_avg_FG2$p.value < .01 , "***", "")))
write.csv(lt1_avg_FG2, file = paste0(path.to.save,tf,"lt1_avg_FG2.csv"))
setwd("R:\\Project\\SeattleMinimumWage\\Stata\\AttenuationPaper\\dofiles\\AEJEP_submission_2020\\code\\")
# Set base directory *******
path.to.root <- "R:\\Project\\SeattleMinimumWage\\Stata\\AttenuationPaper\\dofiles\\AEJEP_submission_2020\\"
# Data
path.to.data <- paste0(path.to.root,"data\\")
# Output
path.to.save <- paste0(path.to.root,"output\\")
test<-readRDS(paste0(path.to.save,stub.save,"_coef_CI_",mode.changes,".Rds")
test<-readRDS(,paste0(path.to.save,stub.save,"_coef_CI_",mode.changes,".Rds")
test<-readRDS(file=paste0(path.to.save,stub.save,"_coef_CI_",mode.changes,".Rds")
test<-readRDS(paste0(path.to.save,stub.save,"_coef_CI_",mode.changes,".Rds"))
stub.save <- "appendix_figure_a11"
test<-readRDS(paste0(path.to.save,stub.save,"_coef_CI_",mode.changes,".Rds"))
mode.changes = "growth_rates"
test<-readRDS(paste0(path.to.save,stub.save,"_coef_CI_",mode.changes,".Rds"))
# Set base directory ******
setwd("R:\\Project\\SeattleMinimumWage\\Stata\\AttenuationPaper\\dofiles\\AEJEP_submission_2020\\code\\code_confidential\\")
# Set base directory *******
path.to.root <- "R:\\Project\\SeattleMinimumWage\\Stata\\AttenuationPaper\\dofiles\\AEJEP_submission_2020\\"
# Data
path.to.data <- paste0(path.to.root,"data\\data_confidential\\")
# Output
path.to.save <- paste0(path.to.root,"output\\output_confidential\\")
test<-readRDS(paste0(path.to.save,stub.save,"_coef_CI_",mode.changes,".Rds"))
View(test)
test <-data.frame(test)
View(test)
write.csv(rbind(app11), file = paste0(path.to.data,"jobs_bins_all.csv"))
app11<-readRDS(paste0(path.to.save,stub.save,"_coef_CI_",mode.changes,".Rds"))
app11 <-data.frame(test)
write.csv(rbind(app11), file = paste0(path.to.data,"jobs_bins_all.csv"))
write.csv(rbind(app11), file = paste0(path.to.save,"jobs_bins_all.csv"))
app11<-readRDS(paste0(path.to.save,stub.save,"_coef_CI_",mode.changes,".Rds"))
cohort.series.DiD <- read.dta13(paste0(path.to.data,stub.DiD,".dta", collapse = ""))
cohort.series.DiD <- data.table(cohort.series.DiD, key = c("region0","yearquarter"))
cohort.series.DiD[ , year := floor(yearquarter/10) ]
# Melt for analysis # goes long so only columns are region, time temp yearquarter N variable value, second command sorts
cohort.series.DiD <- melt(cohort.series.DiD, id.vars = c("region0", "yearquarter","T","year","quarter","date_q"))
cohort.series.DiD <- data.table(cohort.series.DiD, key = c("region0","yearquarter","variable","year"))
# create dY just as the value
cohort.series.DiD[ , dY := value, by = c("region0","yearquarter","variable")]
# Drop 2005 cohort -- N/A for flows
cohort.series.DiD <- cohort.series.DiD[yearquarter > 20061 & region0!=9, ]
cohort.series.DiD <- cohort.series.DiD[yearquarter != 20164, ]
path.to.root <- "R:\\Project\\SeattleMinimumWage\\Stata\\AttenuationPaper\\dofiles\\AEJEP_submission_2020\\"
# Data
path.to.data <- paste0(path.to.root,"data_confidential\\
stub.DiD <- "establishments_samplesize100DiD_bins_prep_all"
stub.DiD <- "establishments_samplesize100DiD_bins_prep_all"
# Set base directory *******
path.to.root <- "R:\\Project\\SeattleMinimumWage\\Stata\\AttenuationPaper\\dofiles\\AEJEP_submission_2020\\"
# Data
path.to.data <- paste0(path.to.root,"\\data_confidential\\")
# Load Did data for Seattle averages
cohort.series.DiD <- read.dta13(paste0(path.to.data,stub.DiD,".dta", collapse = ""))
cohort.series.DiD <- data.table(cohort.series.DiD, key = c("region0","yearquarter"))
cohort.series.DiD[ , year := floor(yearquarter/10) ]
library(data.table)
cohort.series.DiD <- data.table(cohort.series.DiD, key = c("region0","yearquarter"))
cohort.series.DiD[ , year := floor(yearquarter/10) ]
# Melt for analysis # goes long so only columns are region, time temp yearquarter N variable value, second command sorts
cohort.series.DiD <- melt(cohort.series.DiD, id.vars = c("region0", "yearquarter","T","year","quarter","date_q"))
cohort.series.DiD <- data.table(cohort.series.DiD, key = c("region0","yearquarter","variable","year"))
# create dY just as the value
cohort.series.DiD[ , dY := value, by = c("region0","yearquarter","variable")]
# Drop 2005 cohort -- N/A for flows
cohort.series.DiD <- cohort.series.DiD[yearquarter > 20061 & region0!=9, ]
cohort.series.DiD <- cohort.series.DiD[yearquarter != 20164, ]
Y0.Seattle <- cohort.series.DiD[region0 == 1 & year == 2014 & quarter == 2 , list(variable,dY)]
Y0.Seattle <- Y0.Seattle[grepl("d\\_",Y0.Seattle$variable)==FALSE, ]
Y0.Seattle$variable <- paste0("d_",Y0.Seattle$variable)
setnames(Y0.Seattle,"dY","Y0")
results.coefs.all<-readRDS(paste0(path.to.save,stub.save,"_coef_CI_",mode.changes,".Rds"))
results.coefs.all <- merge(results.coefs.all, Y0.Seattle, by = c("variable"), all.x = TRUE, all.y = FALSE, allow.cartesian = TRUE)
setnames(results.coefs.all,"variable","variable_name")
write.csv(rbind(results.coefs.all), file = paste0(path.to.save,"jobs_bins_all.csv"))
appendix_figure_a11_synth_exclKing_growth_rates <- readRDS("R:/Project/SeattleMinimumWage/Stata/AttenuationPaper/dofiles/AEJEP_submission_2020/output/output_confidential/appendix_figure_a11_synth_exclKing_growth_rates.Rds")
View(appendix_figure_a11_synth_exclKing_growth_rates)
appendix_figure_a11_coef_CI_growth_rates <- readRDS("R:/Project/SeattleMinimumWage/Stata/AttenuationPaper/dofiles/AEJEP_submission_2020/output/output_confidential/appendix_figure_a11_coef_CI_growth_rates.Rds")
View(appendix_figure_a11_coef_CI_growth_rates)
